---
title: 以知乎为例试探讨一种万能模拟登陆方式 
description:  
date: 2017-10-02 18:04  
categories:
- 实例
- 爬虫   
- 老博客迁移
tags:  
- python  
 
---

>以我们的日常上网的经验，有时我们好像不必登陆也能进入个人页面，原因大家都知道--cookies，根据这个思路，我们只要获取登陆之后的cookies我们就可以随意访问网站，但是要获取登陆后的cookies必须要先登陆，而现在的网站登陆时都有各种各样的验证码，一个网站一个验证原理（比如知乎的点击倒立文字就很特别），这就给我们登陆时带来了不少麻烦，解决了这个还有那个，遇到一个新的验证方式还需要重新研究，我今天要分享的就是一个笨拙但是却像“万金油 式的方法”--手工+selenium+requests。

 1.总体思路

>大家都知道selenium非常容易模拟登陆，但是却不擅长爬取信息，太慢了，所以我们就发挥它的长处，只用在登陆上，然后把登陆后的cookies传递给requests，然后利用requests去进行下面的爬取工作，各施所长。


 2 .具体代码 

```
python
#_*_coding:utf8_*_
from selenium import webdriver
import requests
import time


#利用selenium登录，获取cookies
br=webdriver.Chrome()
br.get("https://www.zhihu.com/#signin")
br.find_element_by_xpath("//span[contains(text(),'使用密码登录')]").click()
br.find_element_by_xpath("//input[@name='account']").send_keys("*********")
br.find_element_by_xpath("//input[@name='password']").send_keys("**********")
time.sleep(5)#手工点击验证码倒立文字预留时间
br.find_element_by_xpath("//button[contains(text(),'登录')]").click()
time.sleep(3)#网页加载时间
selenium_cookies=br.get_cookies()#把selenium获取的cookies保存到变量，备用。
# print(selenium_cookies)
br.quit()

#接下来由requests接收selenium的cookies，并访问网站
s=requests.Session()
for i in selenium_cookies:
	requests.utils.add_dict_to_cookiejar(s.cookies, {i['name']:i['value']})
headers={
	'Host':'www.zhihu.com',
	'User-Agent':'Mozilla/5.0 (Windows NT 10.0; …) Gecko/20100101 Firefox/55.0',
	'Accept':'text/html,application/xhtml+xm…plication/xml;q=0.9,*/*;q=0.8',
	'Accept-Language':'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
	'Accept-Encoding':'gzip, deflate, br',
	'Connection':'keep-alive',
	'Upgrade-Insecure-Requests':'1',
	'Pragma':'',
	'Cache-Control':'',
}
r=s.get("https://www.zhihu.com",headers=headers).content.decode('utf-8')
print(r)#访问个人中心验证
```
在此次试验中我遇到最大的坑就是selenium的cookies转换成requests的cookiejar对象了，查了好多资料，最终在[官方文档](http://cn.python-requests.org/zh_CN/latest/api.html#cookie)里找到了答案，关于requests的cookie处理及cookiejar对象我会再总结一篇，以上。2017-10-2。